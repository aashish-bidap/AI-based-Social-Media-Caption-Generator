{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from PIL import ImageTk, Image\n",
    "from tkinter import filedialog\n",
    "import numpy as np\n",
    "import tensorflow\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dense, Flatten,Input, Convolution2D, Dropout, LSTM, TimeDistributed, Embedding, Bidirectional, Activation, RepeatVector,Concatenate\n",
    "from keras.models import Sequential, Model\n",
    "from keras.utils import np_utils\n",
    "import random\n",
    "from keras.preprocessing import sequence, image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.applications import vgg16\n",
    "from tensorflow.keras.applications.vgg16 import decode_predictions\n",
    "from gensim.models import Word2Vec,KeyedVectors\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = tk.Tk()\n",
    "root.title('Image Captioning')\n",
    "root.iconbitmap('class.ico')\n",
    "root.resizable(False, False)\n",
    "tit = tk.Label(root, text=\"Portable Image Classifier\", padx=25, pady=6, font=(\"\", 12)).pack()\n",
    "canvas = tk.Canvas(root, height=700, width=1100, bg='grey')\n",
    "canvas.pack()\n",
    "frame = tk.Frame(root, bg='white')\n",
    "frame.place(relwidth=0.8, relheight=0.8, relx=0.1, rely=0.1)\n",
    "chose_image = tk.Button(root, text='Choose Image',\n",
    "                        padx=35, pady=10,\n",
    "                        fg=\"black\", bg=\"grey\", command=load_img)\n",
    "chose_image.pack(side=tk.LEFT)\n",
    "class_image = tk.Button(root, text='Caption Image',\n",
    "                        padx=35, pady=10,\n",
    "                        fg=\"black\", bg=\"grey\", command=classify)\n",
    "class_image.pack(side=tk.RIGHT)\n",
    "recommend_caption = tk.Button(root, text = 'Recommend Captions', padx=35, pady=10,\n",
    "                             fg = \"black\", bg = \"grey\", command=recommend)\n",
    "recommend_caption.pack(side=tk.RIGHT)\n",
    "#vgg_model = vgg16.VGG16(weights='imagenet')\n",
    "model1 = tensorflow.keras.models.load_model('saved_model.hp5')\n",
    "model2 = tensorflow.keras.models.load_model('model_text_categorize.h5')\n",
    "#weights = tensorflow.keras.models.load_model('model.h5')\n",
    "#model= moodel\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img():\n",
    "    global img, image_data\n",
    "    for img_display in frame.winfo_children():\n",
    "        img_display.destroy()\n",
    "\n",
    "    image_data = filedialog.askopenfilename(initialdir=\"/\", title=\"Choose an image\",\n",
    "                                       filetypes=((\"all files\", \"*.*\"), (\"png files\", \"*.png\")))\n",
    "    basewidth = 250 # Processing image for dysplaying\n",
    "    img = Image.open(image_data)\n",
    "    wpercent = (basewidth / float(img.size[0]))\n",
    "    hsize = int((float(img.size[1]) * float(wpercent)))\n",
    "    img = img.resize((basewidth, hsize), Image.ANTIALIAS)\n",
    "    img = ImageTk.PhotoImage(img)\n",
    "    file_name = image_data.split('/')\n",
    "    panel = tk.Label(frame, text= str(file_name[len(file_name)-1]).upper()).pack()\n",
    "    panel_image = tk.Label(frame, image=img).pack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify():\n",
    "    global category\n",
    "    #original = Image.open(image_data)\n",
    "    original = image.load_img(image_data, target_size=(224,224,3))\n",
    "    #original = original.resize((224, 224,3\n",
    "    original = img_to_array(original)\n",
    "    original = np.expand_dims(original, axis=0)\n",
    "    resnet = ResNet50(include_top=False,weights='imagenet',input_shape=(224,224,3),pooling='avg')\n",
    "    test_img = resnet.predict(original).reshape(2048)\n",
    "    with open('word_2_indices.pickle', 'rb') as handle:\n",
    "        word_2_indices_data = pickle.load(handle)\n",
    "    word_2_indices = word_2_indices_data\n",
    "    with open('indices_2_word.pickle', 'rb') as handle:\n",
    "        indices_2_word_data = pickle.load(handle)\n",
    "    indices_2_word = indices_2_word_data\n",
    "    max_len = 40\n",
    "    start_word = [\"<start>\"]\n",
    "    while True:\n",
    "        par_caps = [word_2_indices[i] for i in start_word]\n",
    "        par_caps = sequence.pad_sequences([par_caps], maxlen=max_len, padding='post')\n",
    "        preds = model1.predict([np.array([test_img]), np.array(par_caps)])\n",
    "        word_pred = indices_2_word[np.argmax(preds[0])]\n",
    "        start_word.append(word_pred)\n",
    "        \n",
    "        if word_pred == \"<end>\" or len(start_word) > max_len:\n",
    "            break\n",
    "    label= ' '.join(start_word[1:-1])\n",
    "    model_w2v = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz',binary=True,limit=1000000)\n",
    "    description = label\n",
    "    description = description.replace(r'\\d+','')\n",
    "    spec_chars = [\"!\",'\"',\"#\",\"%\",\"&\",\"'\",\"(\",\")\",\n",
    "                \"*\",\"+\",\",\",\"-\",\".\",\"/\",\":\",\";\",\"<\",\n",
    "                \"=\",\">\",\"?\",\"@\",\"[\",\"\\\\\",\"]\",\"^\",\"_\",\n",
    "                \"`\",\"{\",\"|\",\"}\",\"~\",\"â€“\"]\n",
    "    for char in spec_chars:\n",
    "        description = description.replace(char, ' ')\n",
    "    word_list_t = description.lower().split() \n",
    "    filtered_words = [word for word in word_list_t if word not in stopwords.words('english')]\n",
    "    text = ' '.join(filtered_words)\n",
    "    description = text\n",
    "    description_tokens = list(description.split(\" \"))\n",
    "    token_list=[]\n",
    "    for i in description_tokens:\n",
    "        if len(i) > 3 and i in model_w2v.vocab:\n",
    "            token_list.append(i)\n",
    "        else:\n",
    "            continue\n",
    "    description_tokens_filtered = token_list\n",
    "    _arrays = np.zeros((1, 300))\n",
    "    vec = np.zeros(300).reshape((1, 300))\n",
    "    count = 0\n",
    "    for word in description_tokens_filtered:\n",
    "        vec += model_w2v[word].reshape((1, 300))\n",
    "        count += 1.\n",
    "    if count != 0:\n",
    "        vec /= count\n",
    "    _arrays[0,:] = vec\n",
    "    vectorized_array = pd.DataFrame(_arrays)\n",
    "    pred = model2.predict([vectorized_array.iloc[:,0:300]])\n",
    "    value = np.argmax(pred,axis=-1)\n",
    "    labels = ['adventure','art and music','food','history','manufacturing','nature','science and technology','sports','travel']\n",
    "    category = labels[value.item()]\n",
    "    result = tk.Label(frame, text= str('Caption:') + str(label) + '\\n' + str('Predicted Label :') + str(category)).pack()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend():\n",
    "    captions = pd.read_csv('captions.csv')\n",
    "    is_category = captions['Category'].str.lower()== category\n",
    "    df = captions.loc[is_category]\n",
    "    df.columns = ('Category', 'Caption')\n",
    "    df.head()\n",
    "    caption_list = df['Caption']\n",
    "    result = tk.Label(frame, text = str('Recommended Captions for the label:') + str('\\n')).pack()\n",
    "    count = 1\n",
    "    for caption in caption_list:\n",
    "        result = tk.Label(frame, text = str(count) + str('.') + str(caption)).pack()\n",
    "        count = count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
